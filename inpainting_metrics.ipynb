{"cells":[{"cell_type":"markdown","metadata":{"id":"7KERk0P3Wrc3"},"source":["Code for **\"Inpainting\"** figures $6$, $8$ and 7 (top) from the main paper."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UNHpWeZZWrc7","executionInfo":{"status":"ok","timestamp":1701296782760,"user_tz":360,"elapsed":444,"user":{"displayName":"Zaifu Zhan","userId":"03643249296964869374"}},"outputId":"8b9868f5-0b50-423e-bd70-70ba6d5e1be4"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'deep-image-prior' already exists and is not an empty directory.\n","mv: cannot stat '/panfs/jay/groups/4/zhan1386/yang8597/DL/deep-image-prior': No such file or directory\n"]}],"source":["\"\"\"\n","*Uncomment if running on colab*\n","Set Runtime -> Change runtime type -> Under Hardware Accelerator select GPU in Google Colab\n","\"\"\"\n","!git clone https://github.com/DmitryUlyanov/deep-image-prior\n","!mv /panfs/jay/groups/4/zhan1386/yang8597/DL/deep-image-prior ./"]},{"cell_type":"markdown","metadata":{"id":"awvv2_NFWrc9"},"source":["# Import libs"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"8_PewVV7Wrc9","executionInfo":{"status":"error","timestamp":1701296847258,"user_tz":360,"elapsed":451,"user":{"displayName":"Zaifu Zhan","userId":"03643249296964869374"}},"outputId":"d8b21ea1-df80-42c1-86d7-aa9c20ed0501"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-0281770b8013>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from __future__ import print_function\n","import matplotlib.pyplot as plt\n","#%matplotlib inline\n","\n","import os\n","os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n","\n","import numpy as np\n","from models.resnet import ResNet\n","from models.unet import UNet\n","from models.skip import skip\n","import torch\n","import torch.optim\n","\n","from utils.inpainting_utils import *\n","\n","torch.backends.cudnn.enabled = True\n","torch.backends.cudnn.benchmark =True\n","dtype = torch.cuda.FloatTensor\n","\n","PLOT = True\n","imsize = -1\n","dim_div_by = 64"]},{"cell_type":"markdown","metadata":{"id":"IzlpjfVEWrc9"},"source":["# Choose figure"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f651a-6BWrc-","executionInfo":{"status":"aborted","timestamp":1701296783293,"user_tz":360,"elapsed":8,"user":{"displayName":"Zaifu Zhan","userId":"03643249296964869374"}}},"outputs":[],"source":["## Fig 6\n","# img_path  = 'data/inpainting/vase.png'\n","# mask_path = 'data/inpainting/vase_mask.png'\n","\n","## Fig 8\n","# img_path  = 'data/inpainting/library.png'\n","# mask_path = 'data/inpainting/library_mask.png'\n","\n","## Fig 7 (top)\n","img_path  = 'data/inpainting/kate.png'\n","mask_path = 'data/inpainting/kate_mask.png'\n","\n","# Another text inpainting example\n","# img_path  = 'data/inpainting/peppers.png'\n","# mask_path = 'data/inpainting/peppers_mask.png'\n","\n","NET_TYPE = 'ResNet' # one of skip_depth4|skip_depth2|UNET|ResNet"]},{"cell_type":"markdown","metadata":{"id":"ZZWkKyjUWrc-"},"source":["# Load mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-jXcziMKWrc-","executionInfo":{"status":"aborted","timestamp":1701296783293,"user_tz":360,"elapsed":8,"user":{"displayName":"Zaifu Zhan","userId":"03643249296964869374"}}},"outputs":[],"source":["img_pil, img_np = get_image(img_path, imsize)\n","img_mask_pil, img_mask_np = get_image(mask_path, imsize)"]},{"cell_type":"markdown","metadata":{"id":"UZty2cuBWrc_"},"source":["### Center crop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2WD3NZ5sWrc_","executionInfo":{"status":"aborted","timestamp":1701296783293,"user_tz":360,"elapsed":8,"user":{"displayName":"Zaifu Zhan","userId":"03643249296964869374"}}},"outputs":[],"source":["img_mask_pil = crop_image(img_mask_pil, dim_div_by)\n","img_pil      = crop_image(img_pil, dim_div_by)\n","\n","img_np      = pil_to_np(img_pil)\n","img_mask_np = pil_to_np(img_mask_pil)"]},{"cell_type":"markdown","metadata":{"id":"R7In5AoAWrc_"},"source":["### Visualize"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"exNgZrRZWrc_","executionInfo":{"status":"aborted","timestamp":1701296783293,"user_tz":360,"elapsed":8,"user":{"displayName":"Zaifu Zhan","userId":"03643249296964869374"}}},"outputs":[],"source":["img_mask_var = np_to_torch(img_mask_np).type(dtype)\n","\n","plot_image_grid([img_np, img_mask_np, img_mask_np*img_np], 3,11);"]},{"cell_type":"markdown","metadata":{"id":"wUidv7uxWrdA"},"source":["# Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-YoY4NxyWrdA","executionInfo":{"status":"aborted","timestamp":1701296783294,"user_tz":360,"elapsed":8,"user":{"displayName":"Zaifu Zhan","userId":"03643249296964869374"}}},"outputs":[],"source":["pad = 'reflection' # 'zero'\n","OPT_OVER = 'net'\n","OPTIMIZER = 'adam'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IvN8bKBqWrdA","executionInfo":{"status":"aborted","timestamp":1701296783294,"user_tz":360,"elapsed":8,"user":{"displayName":"Zaifu Zhan","userId":"03643249296964869374"}}},"outputs":[],"source":["if 'vase.png' in img_path:\n","    INPUT = 'meshgrid'\n","    input_depth = 2\n","    LR = 0.01\n","    num_iter = 5001\n","    param_noise = False\n","    show_every = 50\n","    figsize = 5\n","    reg_noise_std = 0.03\n","\n","    net = skip(input_depth, img_np.shape[0],\n","               num_channels_down = [128] * 5,\n","               num_channels_up   = [128] * 5,\n","               num_channels_skip = [0] * 5,\n","               upsample_mode='nearest', filter_skip_size=1, filter_size_up=3, filter_size_down=3,\n","               need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)\n","\n","elif ('kate.png' in img_path) or ('peppers.png' in img_path):\n","    # Same params and net as in super-resolution and denoising\n","    INPUT = 'noise'\n","    input_depth = 32\n","    LR = 0.01\n","    num_iter = 5001\n","    param_noise = False\n","    show_every = 50\n","    figsize = 5\n","    reg_noise_std = 0.03\n","\n","    net = skip(input_depth, img_np.shape[0],\n","               num_channels_down = [128] * 5,\n","               num_channels_up =   [128] * 5,\n","               num_channels_skip =    [128] * 5,\n","               filter_size_up = 3, filter_size_down = 3,\n","               upsample_mode='nearest', filter_skip_size=1,\n","               need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)\n","\n","elif 'library.png' in img_path:\n","\n","    INPUT = 'noise'\n","    input_depth = 1\n","\n","    num_iter = 3001\n","    show_every = 50\n","    figsize = 8\n","    reg_noise_std = 0.00\n","    param_noise = True\n","\n","    if 'skip' in NET_TYPE:\n","\n","        depth = int(NET_TYPE[-1])\n","        net = skip(input_depth, img_np.shape[0],\n","               num_channels_down = [16, 32, 64, 128, 128, 128][:depth],\n","               num_channels_up =   [16, 32, 64, 128, 128, 128][:depth],\n","               num_channels_skip =    [0, 0, 0, 0, 0, 0][:depth],\n","               filter_size_up = 3,filter_size_down = 5,  filter_skip_size=1,\n","               upsample_mode='nearest', # downsample_mode='avg',\n","               need1x1_up=False,\n","               need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)\n","\n","        LR = 0.01\n","\n","    elif NET_TYPE == 'UNET':\n","\n","        net = UNet(num_input_channels=input_depth, num_output_channels=3,\n","                   feature_scale=8, more_layers=1,\n","                   concat_x=False, upsample_mode='deconv',\n","                   pad='zero', norm_layer=torch.nn.InstanceNorm2d, need_sigmoid=True, need_bias=True)\n","\n","        LR = 0.001\n","        param_noise = False\n","\n","    elif NET_TYPE == 'ResNet':\n","\n","        net = ResNet(input_depth, img_np.shape[0], 8, 32, need_sigmoid=True, act_fun='LeakyReLU')\n","\n","        LR = 0.001\n","        param_noise = False\n","\n","    else:\n","        assert False\n","else:\n","    assert False\n","\n","net = net.type(dtype)\n","net_input = get_noise(input_depth, INPUT, img_np.shape[1:]).type(dtype)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bbr7e6VCWrdA","executionInfo":{"status":"aborted","timestamp":1701296783294,"user_tz":360,"elapsed":8,"user":{"displayName":"Zaifu Zhan","userId":"03643249296964869374"}}},"outputs":[],"source":["# Compute number of parameters\n","s  = sum(np.prod(list(p.size())) for p in net.parameters())\n","print ('Number of params: %d' % s)\n","\n","# Loss\n","mse = torch.nn.MSELoss().type(dtype)\n","\n","img_var = np_to_torch(img_np).type(dtype)\n","mask_var = np_to_torch(img_mask_np).type(dtype)"]},{"cell_type":"markdown","metadata":{"id":"yN6-XZYqWrdA"},"source":["# Main loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4cHAccFWrdB","executionInfo":{"status":"aborted","timestamp":1701296783294,"user_tz":360,"elapsed":8,"user":{"displayName":"Zaifu Zhan","userId":"03643249296964869374"}}},"outputs":[],"source":["i = 0\n","out_nps, losses = []\n","def closure():\n","\n","    global i\n","    global out_nps\n","\n","    if param_noise:\n","        for n in [x for x in net.parameters() if len(x.size()) == 4]:\n","            n = n + n.detach().clone().normal_() * n.std() / 50\n","\n","    net_input = net_input_saved\n","    if reg_noise_std > 0:\n","        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n","\n","\n","    out = net(net_input)\n","\n","    total_loss = mse(out * mask_var, img_var * mask_var)\n","    total_loss.backward()\n","\n","    print ('Iteration %05d    Loss %f' % (i, total_loss.item()), '\\r', end='')\n","    if  PLOT and i % show_every == 0:\n","        out_np = torch_to_np(out)\n","        plot_image_grid([np.clip(out_np, 0, 1)], factor=figsize, nrow=1)\n","        out_nps.append(np.clip(out_np, 0, 1))\n","\n","    i += 1\n","\n","    return total_loss\n","\n","net_input_saved = net_input.detach().clone()\n","noise = net_input.detach().clone()\n","\n","p = get_params(OPT_OVER, net, net_input)\n","optimize(OPTIMIZER, p, closure, LR, num_iter)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-_mYhZfWrdB","executionInfo":{"status":"aborted","timestamp":1701296783294,"user_tz":360,"elapsed":8,"user":{"displayName":"Zaifu Zhan","userId":"03643249296964869374"}}},"outputs":[],"source":["len(out_nps)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i1aUovvQWrdB","executionInfo":{"status":"aborted","timestamp":1701296783294,"user_tz":360,"elapsed":8,"user":{"displayName":"Zaifu Zhan","userId":"03643249296964869374"}}},"outputs":[],"source":["import cv2\n","import numpy as np\n","from skimage.metrics import mean_squared_error, peak_signal_noise_ratio\n","from skimage.metrics import structural_similarity as ssim\n","\n","def calculate_psnr_and_mse(imageA, imageB):\n","    mse = mean_squared_error(imageA, imageB)\n","    psnr = peak_signal_noise_ratio(imageA, imageB)\n","    return mse, psnr\n","\n","\n","def calculate_ssim(imageA, imageB):\n","    return ssim(imageA, imageB, data_range=imageB.max() - imageB.min())\n","\n","\n","# Load the images\n","original = img_np\n","# recovered = img_np\n","# recovered = img_mask_np*img_np\n","# recovered = out_nps[0]\n","# recovered = out_nps[50]\n","recovered = out_nps[100]\n","\n","original = np.transpose(original, (1, 2, 0))\n","recovered = np.transpose(recovered, (1, 2, 0))\n","\n","# Convert images to grayscale if they are not\n","if len(original.shape) == 3:\n","    original = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n","if len(recovered.shape) == 3:\n","    recovered = cv2.cvtColor(recovered, cv2.COLOR_BGR2GRAY)\n","\n","mse, psnr = calculate_psnr_and_mse(original, recovered)\n","print(f\"MSE: {mse}, PSNR: {psnr}\")\n","ssim_value = calculate_ssim(original, recovered)\n","print(f\"SSIM: {ssim_value}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iX79RMr0WrdB","executionInfo":{"status":"aborted","timestamp":1701296783294,"user_tz":360,"elapsed":8,"user":{"displayName":"Zaifu Zhan","userId":"03643249296964869374"}}},"outputs":[],"source":["mses = []\n","psnrs = []\n","ssims = []\n","\n","for recovered in out_nps:\n","    # Compute MSE\n","    original = np.transpose(img_np, (1, 2, 0))\n","    recovered = np.transpose(recovered, (1, 2, 0))\n","\n","    # Convert images to grayscale if they are not\n","    if len(original.shape) == 3:\n","        original = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n","    if len(recovered.shape) == 3:\n","        recovered = cv2.cvtColor(recovered, cv2.COLOR_BGR2GRAY)\n","\n","    mse_value, psnr_value = calculate_psnr_and_mse(original, recovered)\n","    mses.append(mse_value)\n","\n","    psnrs.append(psnr_value)\n","\n","    # Compute SSIM\n","    ssim_value = calculate_ssim(original, recovered)\n","    ssims.append(ssim_value)\n","\n","# Plotting the metrics\n","iterations = range(len(out_nps))\n","plt.figure(figsize=(10, 6))\n","plt.plot(iterations, mses, label='MSE')\n","plt.plot(iterations, psnrs, label='PSNR')\n","plt.plot(iterations, ssims, label='SSIM')\n","plt.xlabel('Iteration')\n","plt.ylabel('Metric Value')\n","plt.title('Image Recovery Metrics Over Iterations')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gFxldfHiWrdB","executionInfo":{"status":"aborted","timestamp":1701296783295,"user_tz":360,"elapsed":9,"user":{"displayName":"Zaifu Zhan","userId":"03643249296964869374"}}},"outputs":[],"source":["iterations1 = [50*i for i in iterations]\n","\n","# Plotting the metrics in three separate plots, displayed horizontally\n","fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n","\n","# MSE plot\n","axs[0].plot(iterations1, mses, label='MSE', color='blue')\n","axs[0].set_title('Mean Squared Error')\n","axs[0].set_xlabel('Iteration')\n","axs[0].set_ylabel('MSE Value')\n","axs[0].grid(True)\n","\n","# PSNR plot\n","axs[1].plot(iterations1, psnrs, label='PSNR', color='green')\n","axs[1].set_title('Peak Signal-to-Noise Ratio')\n","axs[1].set_xlabel('Iteration')\n","axs[1].set_ylabel('PSNR Value')\n","axs[1].grid(True)\n","\n","# SSIM plot\n","axs[2].plot(iterations1, ssims, label='SSIM', color='red')\n","axs[2].set_title('Structural Similarity Index')\n","axs[2].set_xlabel('Iteration')\n","axs[2].set_ylabel('SSIM Value')\n","axs[2].grid(True)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dRewLMk8WrdC","executionInfo":{"status":"aborted","timestamp":1701296783295,"user_tz":360,"elapsed":9,"user":{"displayName":"Zaifu Zhan","userId":"03643249296964869374"}}},"outputs":[],"source":["plot_image_grid([np.clip(out_nps[0], 0, 1)], factor=figsize, nrow=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PXBIw4G3WrdC","executionInfo":{"status":"aborted","timestamp":1701296783295,"user_tz":360,"elapsed":8,"user":{"displayName":"Zaifu Zhan","userId":"03643249296964869374"}}},"outputs":[],"source":["img_np.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r0Lejf6DWrdC","executionInfo":{"status":"aborted","timestamp":1701296783295,"user_tz":360,"elapsed":8,"user":{"displayName":"Zaifu Zhan","userId":"03643249296964869374"}}},"outputs":[],"source":["figsize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OR16LiMlWrdC","executionInfo":{"status":"aborted","timestamp":1701296783295,"user_tz":360,"elapsed":8,"user":{"displayName":"Zaifu Zhan","userId":"03643249296964869374"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}